# Awesome Visual Generation Foundations

## Overview

This *awesome list* curates high-quality resources on visual generation (with a strong focus on diffusion), especially **task-agnostic fundamentals** and core principles.

**Inclusion priorities**
- **Peer-reviewed** papers from top conferences/journals.
- Works with **high community traction** (broad citations, active re-implementations, thorough comparisons, lively discussions).

**Maintenance**
- We aim for **daily updates**.

If you find this useful, please **‚≠ê star the repo**.  
Suggestions are welcome‚Äîopen an Issue or submit a PR with vetted, high-signal resources.


## Visual Tokenizer
‚ú®**Latent Diffusion Model without Variational Autoencoder** \
Minglei Shi, Haolin Wang, Wenzhao Zheng, Ziyang Yuan, Xiaoshi Wu, Xintao Wang, Pengfei Wan, Jie Zhou, Jiwen Lu. [arXiv 2510.15301](https://arxiv.org/abs/2510.15301)

‚ú®**Diffusion Transformers with Representation Autoencoders** \
Boyang Zheng, Nanye Ma, Shengbang Tong, Saining Xie. [arXiv 2510.11690](https://arxiv.org/abs/2510.11690v1)

‚ú®**Representation Entanglement for Generation: Training Diffusion Transformers Is Much Easier Than You Think** \
Ge Wu, Shen Zhang, Ruijing Shi, Shanghua Gao, Zhenyuan Chen, Lei Wang, Zhaowei Chen, Hongcheng Gao, Yao Tang, Jian Yang, Ming-Ming Cheng, Xiang Li. [NeurIPS 2025](https://arxiv.org/abs/2507.01467)

‚ú®**REPA-E: Unlocking VAE for End-to-End Tuning with Latent Diffusion Transformers** \
Xingjian Leng, Jaskirat Singh, Yunzhong Hou, Zhenchang Xing, Saining Xie, Liang Zheng. [ICCV 2025](https://arxiv.org/abs/2504.10483)

üî•**Reconstruction vs. Generation: Taming Optimization Dilemma in Latent Diffusion Models** \
Jingfeng Yao, Bin Yang, Xinggang Wang.  [CVPR 2025](https://openaccess.thecvf.com/content/CVPR2025/papers/Yao_Reconstruction_vs._Generation_Taming_Optimization_Dilemma_in_Latent_Diffusion_Models_CVPR_2025_paper.pdf),  **\[VA-VAE\]**

üî•**Representation Alignment for Generation: Training Diffusion Transformers Is Easier Than You Think** \
Sihyun Yu, Sangkyung Kwak, Huiwon Jang, Jongheon Jeong, Jonathan Huang, Jinwoo Shin, Saining Xie. [ICLR 2025](https://arxiv.org/abs/2410.06940), **\[REPA\]**

## Sampling Temperature

‚ú®**Mitigating the Noise Shift for Denoising Generative Models via Noise Awareness Guidance** \
Jincheng Zhong, Boyuan Jiang, Xin Tao, Pengfei Wan, Kun Gai, Mingsheng Long. [arXiv 2510.12497](https://arxiv.org/abs/2510.12497)

**Visual Generation Without Guidance** \
Huayu Chen, Kai Jiang, Kaiwen Zheng, Jianfei Chen, Hang Su, Jun Zhu. [ICML 2025](https://openreview.net/forum?id=gM6aboVgTO)

**Domain Guidance: A Simple Transfer Approach for Pre-trained Diffusion Models**\
Jincheng Zhong, XiangCheng Zhang, Jianmin Wang, Mingsheng Long. [ICLR 2025](https://openreview.net/forum?id=PplM2kDrl3)

üî•**Guiding a Diffusion Model with a Bad Version of Itself**\
Tero Karras, Miika Aittala, Tuomas Kynk√§√§nniemi, Jaakko Lehtinen, Timo Aila, Samuli Laine. [NeurIPS 2024](https://openreview.net/forum?id=bg6fVPVs3s)

## Fast Generation
‚ú®**Scalable GANs with Transformers** \
Sangeek Hyun, MinKyu Lee, Jae-Pil Heo. [arXiv 2509.24935](https://arxiv.org/abs/2509.24935)

üî•**Mean Flows for One-step Generative Modeling** \
Zhengyang Geng, Mingyang Deng, Xingjian Bai, J. Zico Kolter, Kaiming He. [NeurIPS 2025](https://arxiv.org/abs/2505.13447)

üî•**Simplifying, Stabilizing and Scaling Continuous-Time Consistency Models**\
Cheng Lu, and Yang Song. [ICLR 2025](https://arxiv.org/abs/2410.11081)

üî•**One Step Diffusion via Shortcut Models**\
Kevin Frans, Danijar Hafner, Sergey Levine, Pieter Abbeel. [ICLR 2025](https://openreview.net/forum?id=OlzB6LnXcS)

## Post Training

**Flow-GRPO: Training Flow Matching Models via Online RL** \
Jie Liu, Gongye Liu, Jiajun Liang, Yangguang Li, Jiaheng Liu, Xintao Wang, Pengfei Wan, Di Zhang, Wanli Ouyang. [NeurIPS 2025](https://arxiv.org/abs/2505.05470)

**Direct Discriminative Optimization: Your Likelihood-Based Visual Generative Model is Secretly a GAN Discriminator** \
Kaiwen Zheng, Yongxin Chen, Huayu Chen, Guande He, Ming-Yu Liu, Jun Zhu, Qinsheng Zhang. [ICML 2025](https://openreview.net/forum?id=OJ6WE7F8tK)

**Diffusion Tuning: Transferring Diffusion Models via Chain of Forgetting** \
Jincheng Zhong, Xingzhuo Guo, Jiaxiang Dong, Mingsheng Long. [NeurIPS 2024](https://openreview.net/forum?id=S98OzJD3jn)

## Training Tricks

**On the Importance of Noise Scheduling for Diffusion Models** \
Ting Chen. [arXiv 2301.10972](https://arxiv.org/abs/2301.10972)

## Miscellaneous

**Is Noise Conditioning Necessary for Denoising Generative Models?** \
Qiao Sun, Zhicheng Jiang, Hanhong Zhao, Kaiming He. [ICML 2025](https://openreview.net/pdf?id=pTSWi6RTtJ)
